{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', \n",
    "                  'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', \n",
    "                  'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', \n",
    "                  'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', \n",
    "                  'relief', 'remorse', 'sadness', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.load(\"../data/goemotions-test.pth\") # TensorDataset: (input_ids, attention_mask, labels)\n",
    "labels = test.tensors[2].numpy()\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = np.load(\"goemotions-probs.npy\")\n",
    "probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 21123\n",
      "Actual Emotions: ['excitement']\n",
      "Predicted Emotions: ['admiration', 'amusement', 'annoyance', 'approval', 'curiosity', 'disappointment', 'disapproval', 'gratitude', 'joy', 'love', 'optimism', 'realization', 'neutral']\n",
      "\n",
      "\n",
      "Actual Emotions: ['pride']\n",
      "Predicted Emotions: ['admiration', 'amusement', 'annoyance', 'approval', 'curiosity', 'disappointment', 'disapproval', 'gratitude', 'joy', 'love', 'optimism', 'realization', 'neutral']\n",
      "\n",
      "\n",
      "Actual Emotions: ['joy']\n",
      "Predicted Emotions: ['admiration', 'amusement', 'annoyance', 'approval', 'curiosity', 'disappointment', 'disapproval', 'gratitude', 'joy', 'love', 'optimism', 'realization', 'neutral']\n",
      "\n",
      "\n",
      "Actual Emotions: ['neutral']\n",
      "Predicted Emotions: ['admiration', 'amusement', 'annoyance', 'approval', 'curiosity', 'disappointment', 'disapproval', 'gratitude', 'joy', 'love', 'optimism', 'realization', 'neutral']\n",
      "\n",
      "\n",
      "Actual Emotions: ['neutral']\n",
      "Predicted Emotions: ['admiration', 'amusement', 'annoyance', 'approval', 'curiosity', 'disappointment', 'disapproval', 'gratitude', 'joy', 'love', 'optimism', 'realization', 'neutral']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "misclassified = np.where(np.any(preds != labels, axis=1))[0]\n",
    "print(f\"Number of misclassified samples: {len(misclassified)}\")\n",
    "for index in misclassified[:5]:\n",
    "    # print(\"Text:\", test[index][0])\n",
    "    print(f\"Actual Emotions: {[emotion_labels[i] for i, label in enumerate(labels[index]) if label == 1]}\")\n",
    "    print(f\"Predicted Emotions: {[emotion_labels[i] for i, label in enumerate(preds[index]) if label == 1]}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.08      1.00      0.15      1675\n",
      "     amusement       0.04      1.00      0.08       873\n",
      "         anger       0.00      0.00      0.00       835\n",
      "     annoyance       0.07      1.00      0.13      1422\n",
      "      approval       0.08      1.00      0.15      1729\n",
      "        caring       0.00      0.00      0.00       605\n",
      "     confusion       0.00      0.00      0.00       707\n",
      "     curiosity       0.05      1.00      0.09       953\n",
      "        desire       0.00      0.00      0.00       383\n",
      "disappointment       0.04      1.00      0.08       835\n",
      "   disapproval       0.06      1.00      0.11      1175\n",
      "       disgust       0.00      0.00      0.00       570\n",
      " embarrassment       0.00      0.00      0.00       258\n",
      "    excitement       0.00      0.00      0.00       513\n",
      "          fear       0.00      0.00      0.00       353\n",
      "     gratitude       0.05      1.00      0.10      1135\n",
      "         grief       0.00      0.00      0.00        63\n",
      "           joy       0.04      1.00      0.08       838\n",
      "          love       0.04      1.00      0.07       815\n",
      "   nervousness       0.00      0.00      0.00       185\n",
      "      optimism       0.04      1.00      0.07       804\n",
      "         pride       0.00      0.00      0.00       143\n",
      "   realization       0.04      1.00      0.08       888\n",
      "        relief       0.00      0.00      0.00       110\n",
      "       remorse       0.00      0.00      0.00       229\n",
      "       sadness       0.00      0.00      0.00       696\n",
      "      surprise       0.00      0.00      0.00       550\n",
      "       neutral       0.26      1.00      0.42      5546\n",
      "\n",
      "     micro avg       0.07      0.75      0.12     24888\n",
      "     macro avg       0.03      0.46      0.06     24888\n",
      "  weighted avg       0.09      0.75      0.15     24888\n",
      "   samples avg       0.07      0.75      0.12     24888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecal/.local/share/virtualenvs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecal/.local/share/virtualenvs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (hamming_loss, accuracy_score, jaccard_score,\n",
    "                             precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, average_precision_score, \n",
    "                             classification_report)\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(labels, preds, target_names=emotion_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Accuracy: 0.0000\n",
      "Average Precision: 0.0421\n"
     ]
    }
   ],
   "source": [
    "exact_match_accuracy = accuracy_score(labels, preds)\n",
    "print(f\"Exact Match Accuracy: {exact_match_accuracy:.4f}\")\n",
    "\n",
    "averagePrecision = average_precision_score(labels, probs, average='macro')\n",
    "print(f\"Average Precision: {averagePrecision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.4432\n",
      "Exact Match Ratio: 0.0000\n",
      "Jaccard Similarity: 0.0675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hammingLoss = hamming_loss(labels, preds)\n",
    "print(\"Hamming Loss: {:.4f}\".format(hammingLoss))\n",
    "\n",
    "exactMatchRatio = accuracy_score(labels, preds)\n",
    "print(\"Exact Match Ratio: {:.4f}\".format(exactMatchRatio))\n",
    "\n",
    "jaccardSimilarity = jaccard_score(labels, preds, average='samples')\n",
    "print(\"Jaccard Similarity: {:.4f}\\n\".format(jaccardSimilarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion              ROC-AUC    PR-AUC    \n",
      "----------------------------------------\n",
      "admiration           0.5000     0.0793\n",
      "amusement            0.5000     0.0413\n",
      "anger                0.5000     0.0395\n",
      "annoyance            0.5000     0.0673\n",
      "approval             0.5000     0.0819\n",
      "caring               0.5000     0.0286\n",
      "confusion            0.5000     0.0335\n",
      "curiosity            0.5000     0.0451\n",
      "desire               0.5000     0.0181\n",
      "disappointment       0.5000     0.0395\n",
      "disapproval          0.5000     0.0556\n",
      "disgust              0.5000     0.0270\n",
      "embarrassment        0.5000     0.0122\n",
      "excitement           0.5000     0.0243\n",
      "fear                 0.5000     0.0167\n",
      "gratitude            0.5000     0.0537\n",
      "grief                0.5000     0.0030\n",
      "joy                  0.5000     0.0397\n",
      "love                 0.5000     0.0386\n",
      "nervousness          0.5000     0.0088\n",
      "optimism             0.5000     0.0381\n",
      "pride                0.5000     0.0068\n",
      "realization          0.5000     0.0420\n",
      "relief               0.5000     0.0052\n",
      "remorse              0.5000     0.0108\n",
      "sadness              0.5000     0.0329\n",
      "surprise             0.5000     0.0260\n",
      "neutral              0.5000     0.2626\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Emotion':<20} {'ROC-AUC':<10} {'PR-AUC':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, label in enumerate(emotion_labels):\n",
    "    roc_auc = roc_auc_score(labels[:, i], probs[:, i])\n",
    "    pr_auc = average_precision_score(labels[:, i], probs[:, i])\n",
    "    print(f\"{label:<20} {roc_auc:.4f}     {pr_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
